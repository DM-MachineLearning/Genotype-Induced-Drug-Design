nohup: ignoring input
Number of batches:  36
[val] epoch=0 val_loss=3.6851
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=36, val_loss=3.6851)
[train] epoch=1 step=50 loss=3.5119 lr=1.28e-06
[val] epoch=1 val_loss=3.1105
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=72, val_loss=3.1105)
[train] epoch=2 step=100 loss=2.8319 lr=2.53e-06
[val] epoch=2 val_loss=2.8046
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=108, val_loss=2.8046)
[val] epoch=3 val_loss=2.6963
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=144, val_loss=2.6963)
[train] epoch=4 step=150 loss=2.7060 lr=3.77e-06
[val] epoch=4 val_loss=2.6448
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=180, val_loss=2.6448)
[train] epoch=5 step=200 loss=2.6796 lr=5.03e-06
[val] epoch=5 val_loss=2.6106
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=216, val_loss=2.6106)
[train] epoch=6 step=250 loss=2.6114 lr=6.28e-06
[val] epoch=6 val_loss=2.5845
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=252, val_loss=2.5845)
[val] epoch=7 val_loss=2.5627
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=288, val_loss=2.5627)
[train] epoch=8 step=300 loss=2.5103 lr=7.52e-06
[val] epoch=8 val_loss=2.5441
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=324, val_loss=2.5441)
[train] epoch=9 step=350 loss=2.5888 lr=8.77e-06
[val] epoch=9 val_loss=2.5261
[INFO] Saved checkpoint to checkpoints/encoder_pretrain_2026-01-10_15-55-23/best_encoder.pt (step=360, val_loss=2.5261)
[INFO] Saved loss plot to checkpoints/encoder_pretrain_2026-01-10_15-55-23/training_losses.png

[INFO] Computing final evaluation metrics...

======================================================================
ENCODER CAPACITY EVALUATION METRICS
======================================================================

ðŸ“Š Reconstruction Performance:
  â€¢ Loss:              2.5284
  â€¢ Perplexity:        12.53
  â€¢ Token Accuracy:    24.13%
  â€¢ Sequence Accuracy: 0.00%

ðŸ”¬ Latent Space Statistics:
  â€¢ Mean (mu):         -0.0191
  â€¢ Std (mu):          0.5036
  â€¢ Mean Variance:     0.7330
  â€¢ Pairwise Distance: 16.2237

ðŸ“ˆ Samples Evaluated: 127
======================================================================

[INFO] Saved evaluation metrics to checkpoints/encoder_pretrain_2026-01-10_15-55-23/evaluation_metrics.json

[INFO] Collecting latent space samples for visualization...
[INFO] Saved latent distribution plot to checkpoints/encoder_pretrain_2026-01-10_15-55-23/latent_distribution.png

[INFO] Pretraining complete! Checkpoints and plots saved to checkpoints/encoder_pretrain_2026-01-10_15-55-23
